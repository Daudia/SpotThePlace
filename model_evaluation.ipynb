{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from spottheplace import data_to_dataframe\n",
    "from spottheplace import france_region_to_dataframe\n",
    "from spottheplace.ml.utils import AddMask\n",
    "\n",
    "df_4countries = data_to_dataframe(\"\") # path to the test data folder\n",
    "df_FranceRegions = france_region_to_dataframe(\"\") # path to the test data folder for France\n",
    "\n",
    "countries_labels = {0: 'France', 1: 'Japan',\n",
    "                    2: 'Mexico', 3: 'South Africa'}\n",
    "\n",
    "regions_labels = {0: 'Auvergne-Rhône-Alpes', 1: 'Bourgogne-Franche-Comté',\n",
    "                  2: 'Bretagne', 3: 'Centre-Val de Loire', 4: 'Corse',\n",
    "                  5: 'Grand Est', 6: 'Hauts-de-France', 7: 'Normandie',\n",
    "                  8: 'Nouvelle-Aquitaine', 9: 'Occitanie', 10: 'Pays de la Loire',\n",
    "                  11: \"Provence-Alpes-Côte-d'Azur\", 12: 'Île-de-France'}\n",
    "\n",
    "def compute_metrics(true_labels, predicted_labels):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(true_labels, predicted_labels),\n",
    "        \"precision\": precision_score(true_labels, predicted_labels, average='weighted'),\n",
    "        \"recall\": recall_score(true_labels, predicted_labels, average='weighted'),\n",
    "        \"f1\": f1_score(true_labels, predicted_labels, average='weighted'),\n",
    "        \"confusion_matrix\": confusion_matrix(true_labels, predicted_labels)\n",
    "    }\n",
    "    print(\"Accuracy:\", metrics['accuracy'])\n",
    "    print(\"Precision:\", metrics[\"precision\"])\n",
    "    print(\"Recall:\", metrics[\"recall\"])\n",
    "    print(\"F1:\", metrics[\"f1\"])\n",
    "    print(\"Confusion matrix:\\n\", metrics[\"confusion_matrix\"])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Countries classification (France, Japan, South Africa, Mexico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "\n",
    "# Define the model and load the weights\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, 4) # 4 countries\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation to apply to the images for ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    AddMask(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "label_pred = []\n",
    "\n",
    "for index, row in df_4countries.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    class_idx = output.argmax(dim=1).item()\n",
    "    output_class = countries_labels[class_idx]\n",
    "    label_pred.append(output_class)\n",
    "\n",
    "df = df_4countries.copy()\n",
    "df['label_pred'] = label_pred\n",
    "\n",
    "metrics = compute_metrics(df['label'], df['label_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France Regions classification (13 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "\n",
    "# Define the model and load the weights\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, 13)  # 13 regions\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation to apply to the images for ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    AddMask(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "label_pred = []\n",
    "top3_correct = 0\n",
    "\n",
    "for index, row in df_FranceRegions.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    _, top3_idx = torch.topk(output, 3, dim=1)\n",
    "    top3_idx = top3_idx.squeeze().tolist()\n",
    "    output_class = regions_labels[output.argmax(dim=1).item()]\n",
    "    true_label = row['label']\n",
    "    label_pred.append(output_class)\n",
    "\n",
    "    # Compute top-3 accuracy for the regions\n",
    "    if true_label in [regions_labels[idx] for idx in top3_idx]:\n",
    "        top3_correct += 1\n",
    "\n",
    "df = df_FranceRegions.copy()\n",
    "df['label_pred'] = label_pred\n",
    "\n",
    "metrics = compute_metrics(df['label'], df['label_pred'])\n",
    "top3_accuracy = top3_correct / len(df)\n",
    "print(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Countries classification (France, Japan, South Africa, Mexico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "\n",
    "# Define the model and load the weights\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=4)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Define the image processor for the ViT model from Hugging Face\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "label_pred = []\n",
    "\n",
    "for index, row in df_4countries.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    input_tensor = inputs['pixel_values']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    class_idx = output.logits.argmax(dim=1).item()\n",
    "    output_class = countries_labels[class_idx]\n",
    "    print(f\"Prediction: {output_class}\", f\"True label: {row['label']}\")\n",
    "\n",
    "    label_pred.append(output_class)\n",
    "\n",
    "df = df_4countries.copy()\n",
    "df['label_pred'] = label_pred\n",
    "\n",
    "metrics = compute_metrics(df['label'], df['label_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Countries classification (France, Japan, South Africa, Mexico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"\"\n",
    "\n",
    "# Define the model and load the weights\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Define the transformation to apply to the images for ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    AddMask(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "long_preds = []\n",
    "lat_preds = []\n",
    "dist_pred = []\n",
    "\n",
    "for index, row in df_FranceRegions.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    long, lat = row['long'], row['lat']\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    long_preds.append(max(min(output[0][0].item(), 180), -180))\n",
    "    lat_preds.append(max(min(output[0][1].item(), 90), -90))\n",
    "\n",
    "    distance = geodesic((lat, long), (lat_preds[-1], long_preds[-1])).kilometers\n",
    "    dist_pred.append(distance)\n",
    "\n",
    "df = df_FranceRegions.copy()\n",
    "df['long_pred'] = long_preds\n",
    "df['lat_pred'] = lat_preds\n",
    "df['dist_pred'] = dist_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the errors\n",
    "df['long_error'] = df['long'] - df['long_pred']\n",
    "df['lat_error'] = df['lat'] - df['lat_pred']\n",
    "\n",
    "# Configure subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False)\n",
    "\n",
    "# Distribution of longitude error\n",
    "sns.histplot(df['long_error'], kde=True, ax=axes[0], color='blue')\n",
    "axes[0].set_title('Distribution of Longitude Error')\n",
    "axes[0].set_xlabel('Longitude Error (°)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Distribution of latitude error\n",
    "sns.histplot(df['lat_error'], kde=True, ax=axes[1], color='green')\n",
    "axes[1].set_title('Distribution of Latitude Error')\n",
    "axes[1].set_xlabel('Latitude Error (°)')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "# Distribution of distance error\n",
    "sns.histplot(df['dist_pred'], kde=True, ax=axes[2], color='red')\n",
    "axes[2].set_title('Distribution of Distance Error')\n",
    "axes[2].set_xlabel('Distance Error (km)')\n",
    "axes[2].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean Longitude Error:\", round(df['long_error'].mean(), 3), \"degrees\")\n",
    "print(\"Mean Latitude Error:\", round(df['lat_error'].mean(), 3), \"degrees\")\n",
    "print(\"Mean Distance Error:\", int(df['dist_pred'].mean()), \"km\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
